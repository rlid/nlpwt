{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:47:59.443361667Z",
     "start_time": "2023-12-22T20:47:57.190606098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['XNLI',\n 'tydiqa',\n 'SQuAD',\n 'PAN-X.af',\n 'PAN-X.ar',\n 'PAN-X.bg',\n 'PAN-X.bn',\n 'PAN-X.de',\n 'PAN-X.el',\n 'PAN-X.en',\n 'PAN-X.es',\n 'PAN-X.et',\n 'PAN-X.eu',\n 'PAN-X.fa',\n 'PAN-X.fi',\n 'PAN-X.fr',\n 'PAN-X.he',\n 'PAN-X.hi',\n 'PAN-X.hu',\n 'PAN-X.id',\n 'PAN-X.it',\n 'PAN-X.ja',\n 'PAN-X.jv',\n 'PAN-X.ka',\n 'PAN-X.kk',\n 'PAN-X.ko',\n 'PAN-X.ml',\n 'PAN-X.mr',\n 'PAN-X.ms',\n 'PAN-X.my',\n 'PAN-X.nl',\n 'PAN-X.pt',\n 'PAN-X.ru',\n 'PAN-X.sw',\n 'PAN-X.ta',\n 'PAN-X.te',\n 'PAN-X.th',\n 'PAN-X.tl',\n 'PAN-X.tr',\n 'PAN-X.ur',\n 'PAN-X.vi',\n 'PAN-X.yo',\n 'PAN-X.zh',\n 'MLQA.ar.ar',\n 'MLQA.ar.de',\n 'MLQA.ar.vi',\n 'MLQA.ar.zh',\n 'MLQA.ar.en',\n 'MLQA.ar.es',\n 'MLQA.ar.hi',\n 'MLQA.de.ar',\n 'MLQA.de.de',\n 'MLQA.de.vi',\n 'MLQA.de.zh',\n 'MLQA.de.en',\n 'MLQA.de.es',\n 'MLQA.de.hi',\n 'MLQA.vi.ar',\n 'MLQA.vi.de',\n 'MLQA.vi.vi',\n 'MLQA.vi.zh',\n 'MLQA.vi.en',\n 'MLQA.vi.es',\n 'MLQA.vi.hi',\n 'MLQA.zh.ar',\n 'MLQA.zh.de',\n 'MLQA.zh.vi',\n 'MLQA.zh.zh',\n 'MLQA.zh.en',\n 'MLQA.zh.es',\n 'MLQA.zh.hi',\n 'MLQA.en.ar',\n 'MLQA.en.de',\n 'MLQA.en.vi',\n 'MLQA.en.zh',\n 'MLQA.en.en',\n 'MLQA.en.es',\n 'MLQA.en.hi',\n 'MLQA.es.ar',\n 'MLQA.es.de',\n 'MLQA.es.vi',\n 'MLQA.es.zh',\n 'MLQA.es.en',\n 'MLQA.es.es',\n 'MLQA.es.hi',\n 'MLQA.hi.ar',\n 'MLQA.hi.de',\n 'MLQA.hi.vi',\n 'MLQA.hi.zh',\n 'MLQA.hi.en',\n 'MLQA.hi.es',\n 'MLQA.hi.hi',\n 'XQuAD.ar',\n 'XQuAD.de',\n 'XQuAD.vi',\n 'XQuAD.zh',\n 'XQuAD.en',\n 'XQuAD.es',\n 'XQuAD.hi',\n 'XQuAD.el',\n 'XQuAD.ru',\n 'XQuAD.th',\n 'XQuAD.tr',\n 'bucc18.de',\n 'bucc18.fr',\n 'bucc18.zh',\n 'bucc18.ru',\n 'PAWS-X.de',\n 'PAWS-X.en',\n 'PAWS-X.es',\n 'PAWS-X.fr',\n 'PAWS-X.ja',\n 'PAWS-X.ko',\n 'PAWS-X.zh',\n 'tatoeba.afr',\n 'tatoeba.ara',\n 'tatoeba.ben',\n 'tatoeba.bul',\n 'tatoeba.deu',\n 'tatoeba.cmn',\n 'tatoeba.ell',\n 'tatoeba.est',\n 'tatoeba.eus',\n 'tatoeba.fin',\n 'tatoeba.fra',\n 'tatoeba.heb',\n 'tatoeba.hin',\n 'tatoeba.hun',\n 'tatoeba.ind',\n 'tatoeba.ita',\n 'tatoeba.jav',\n 'tatoeba.jpn',\n 'tatoeba.kat',\n 'tatoeba.kaz',\n 'tatoeba.kor',\n 'tatoeba.mal',\n 'tatoeba.mar',\n 'tatoeba.nld',\n 'tatoeba.pes',\n 'tatoeba.por',\n 'tatoeba.rus',\n 'tatoeba.spa',\n 'tatoeba.swh',\n 'tatoeba.tam',\n 'tatoeba.tel',\n 'tatoeba.tgl',\n 'tatoeba.tha',\n 'tatoeba.tur',\n 'tatoeba.urd',\n 'tatoeba.vie',\n 'udpos.Afrikaans',\n 'udpos.Arabic',\n 'udpos.Basque',\n 'udpos.Bulgarian',\n 'udpos.Dutch',\n 'udpos.English',\n 'udpos.Estonian',\n 'udpos.Finnish',\n 'udpos.French',\n 'udpos.German',\n 'udpos.Greek',\n 'udpos.Hebrew',\n 'udpos.Hindi',\n 'udpos.Hungarian',\n 'udpos.Indonesian',\n 'udpos.Italian',\n 'udpos.Japanese',\n 'udpos.Kazakh',\n 'udpos.Korean',\n 'udpos.Chinese',\n 'udpos.Marathi',\n 'udpos.Persian',\n 'udpos.Portuguese',\n 'udpos.Russian',\n 'udpos.Spanish',\n 'udpos.Tagalog',\n 'udpos.Tamil',\n 'udpos.Telugu',\n 'udpos.Thai',\n 'udpos.Turkish',\n 'udpos.Urdu',\n 'udpos.Vietnamese',\n 'udpos.Yoruba']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names('xtreme')\n",
    "xtreme_subsets"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['PAN-X.af',\n 'PAN-X.ar',\n 'PAN-X.bg',\n 'PAN-X.bn',\n 'PAN-X.de',\n 'PAN-X.el',\n 'PAN-X.en',\n 'PAN-X.es',\n 'PAN-X.et',\n 'PAN-X.eu',\n 'PAN-X.fa',\n 'PAN-X.fi',\n 'PAN-X.fr',\n 'PAN-X.he',\n 'PAN-X.hi',\n 'PAN-X.hu',\n 'PAN-X.id',\n 'PAN-X.it',\n 'PAN-X.ja',\n 'PAN-X.jv',\n 'PAN-X.ka',\n 'PAN-X.kk',\n 'PAN-X.ko',\n 'PAN-X.ml',\n 'PAN-X.mr',\n 'PAN-X.ms',\n 'PAN-X.my',\n 'PAN-X.nl',\n 'PAN-X.pt',\n 'PAN-X.ru',\n 'PAN-X.sw',\n 'PAN-X.ta',\n 'PAN-X.te',\n 'PAN-X.th',\n 'PAN-X.tl',\n 'PAN-X.tr',\n 'PAN-X.ur',\n 'PAN-X.vi',\n 'PAN-X.yo',\n 'PAN-X.zh']"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith('PAN')]\n",
    "panx_subsets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:47:59.444575070Z",
     "start_time": "2023-12-22T20:47:59.442208095Z"
    }
   },
   "id": "a34b46b1efaee61a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'ner_tags', 'langs'],\n        num_rows: 20000\n    })\n    validation: Dataset({\n        features: ['tokens', 'ner_tags', 'langs'],\n        num_rows: 10000\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags', 'langs'],\n        num_rows: 10000\n    })\n})"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "load_dataset('xtreme', name='PAN-X.de')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:01.133411998Z",
     "start_time": "2023-12-22T20:47:59.442577959Z"
    }
   },
   "id": "3d7ff500c9f06a84",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "langs = ['de', 'fr', 'it', 'en']\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "\n",
    "for lang, frac in zip(langs, fracs):\n",
    "    ds = load_dataset('xtreme', name=f'PAN-X.{lang}')\n",
    "    for set_name in ds:\n",
    "        panx_ch[lang][set_name] = ds[set_name].shuffle(seed=0).select(range(int(frac * ds[set_name].num_rows)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:06.610851413Z",
     "start_time": "2023-12-22T20:48:01.134826568Z"
    }
   },
   "id": "a1b80105f6f98f25",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "         de        fr        it        en\n0  0.628372  0.228771  0.083916  0.058941",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>de</th>\n      <th>fr</th>\n      <th>it</th>\n      <th>en</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.628372</td>\n      <td>0.228771</td>\n      <td>0.083916</td>\n      <td>0.058941</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "num_samples = pd.DataFrame({lang: [panx_ch[lang]['train'].num_rows] for lang in langs})\n",
    "num_samples / num_samples.iloc[0].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:06.623048187Z",
     "start_time": "2023-12-22T20:48:06.613654103Z"
    }
   },
   "id": "e283257bca125710",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'tokens': ['2.000',\n  'Einwohnern',\n  'an',\n  'der',\n  'Danziger',\n  'Bucht',\n  'in',\n  'der',\n  'polnischen',\n  'Woiwodschaft',\n  'Pommern',\n  '.'],\n 'ner_tags': [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0],\n 'langs': ['de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de',\n  'de']}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch['de']['train'][0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:06.701855619Z",
     "start_time": "2023-12-22T20:48:06.622653283Z"
    }
   },
   "id": "9a68976d3751dd03",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None),\n 'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_ch['de']['train'].features"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:06.702709510Z",
     "start_time": "2023-12-22T20:48:06.663515886Z"
    }
   },
   "id": "f5e8521415bb9ffe",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'B-LOC'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = panx_ch['de']['train'].features['ner_tags'].feature\n",
    "tags\n",
    "tags.int2str(5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:06.703399004Z",
     "start_time": "2023-12-22T20:48:06.663873998Z"
    }
   },
   "id": "211ab048736289d3",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "panx_de = panx_ch['de'].map(lambda batch: {'ner_tags_str': [tags.int2str(i) for i in batch['ner_tags']]})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:06.703965204Z",
     "start_time": "2023-12-22T20:48:06.664183049Z"
    }
   },
   "id": "6f269f1654bf9ee5",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n        num_rows: 12580\n    })\n    validation: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n        num_rows: 6290\n    })\n    test: Dataset({\n        features: ['tokens', 'ner_tags', 'langs', 'ner_tags_str'],\n        num_rows: 6290\n    })\n})"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_de"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:06.704687880Z",
     "start_time": "2023-12-22T20:48:06.664419858Z"
    }
   },
   "id": "e09f7b9041019436",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          tokens  ner_tags langs ner_tags_str\n0          2.000         0    de            O\n1     Einwohnern         0    de            O\n2             an         0    de            O\n3            der         0    de            O\n4       Danziger         5    de        B-LOC\n5          Bucht         6    de        I-LOC\n6             in         0    de            O\n7            der         0    de            O\n8     polnischen         5    de        B-LOC\n9   Woiwodschaft         5    de        B-LOC\n10       Pommern         6    de        I-LOC\n11             .         0    de            O",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n      <th>ner_tags</th>\n      <th>langs</th>\n      <th>ner_tags_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.000</td>\n      <td>0</td>\n      <td>de</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Einwohnern</td>\n      <td>0</td>\n      <td>de</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>an</td>\n      <td>0</td>\n      <td>de</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>der</td>\n      <td>0</td>\n      <td>de</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Danziger</td>\n      <td>5</td>\n      <td>de</td>\n      <td>B-LOC</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Bucht</td>\n      <td>6</td>\n      <td>de</td>\n      <td>I-LOC</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>in</td>\n      <td>0</td>\n      <td>de</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>der</td>\n      <td>0</td>\n      <td>de</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>polnischen</td>\n      <td>5</td>\n      <td>de</td>\n      <td>B-LOC</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Woiwodschaft</td>\n      <td>5</td>\n      <td>de</td>\n      <td>B-LOC</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Pommern</td>\n      <td>6</td>\n      <td>de</td>\n      <td>I-LOC</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>.</td>\n      <td>0</td>\n      <td>de</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de['train'][0]\n",
    "pd.DataFrame(de_example)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:06.720746551Z",
     "start_time": "2023-12-22T20:48:06.664764970Z"
    }
   },
   "id": "5894b29af2307914",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "             LOC   ORG   PER\ntrain       6186  5366  5810\nvalidation  3172  2683  2893\ntest        3180  2573  3071",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LOC</th>\n      <th>ORG</th>\n      <th>PER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>train</th>\n      <td>6186</td>\n      <td>5366</td>\n      <td>5810</td>\n    </tr>\n    <tr>\n      <th>validation</th>\n      <td>3172</td>\n      <td>2683</td>\n      <td>2893</td>\n    </tr>\n    <tr>\n      <th>test</th>\n      <td>3180</td>\n      <td>2573</td>\n      <td>3071</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset['ner_tags_str']:\n",
    "        row = [tag.split('-')[1] for tag in row if tag.startswith('B')]\n",
    "        split2freqs[split] += Counter(row) \n",
    "\n",
    "pd.DataFrame.from_dict(split2freqs, orient='index')        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:06.928117294Z",
     "start_time": "2023-12-22T20:48:06.671686357Z"
    }
   },
   "id": "93cf47156ad16af8",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [0, 21763, 37456, 15555, 5161, 7, 2356, 5753, 38, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = 'bert-base-cased'\n",
    "xlmr_model_name = 'xlm-roberta-base'\n",
    "\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)\n",
    "\n",
    "text = 'Jack Sparrow loves New York!'\n",
    "xlmr_tokenizer(text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:09.739881529Z",
     "start_time": "2023-12-22T20:48:06.928923953Z"
    }
   },
   "id": "b05cfdc7959cb6a",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       0      1      2       3      4    5     6      7      8     9\n0  [CLS]   Jack    Spa  ##rrow  loves  New  York      !  [SEP]  None\n1    <s>  ▁Jack  ▁Spar     row  ▁love    s  ▁New  ▁York      !  </s>",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[CLS]</td>\n      <td>Jack</td>\n      <td>Spa</td>\n      <td>##rrow</td>\n      <td>loves</td>\n      <td>New</td>\n      <td>York</td>\n      <td>!</td>\n      <td>[SEP]</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()\n",
    "\n",
    "pd.DataFrame([bert_tokens, xlmr_tokens])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:09.747733638Z",
     "start_time": "2023-12-22T20:48:09.743866191Z"
    }
   },
   "id": "dc9c6851ad2928f5",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('<s>▁Jack▁Sparrow▁loves▁New▁York!</s>',\n '<s> Jack Sparrow loves New York!</s>')"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(xlmr_tokens), ''.join(xlmr_tokens).replace(u'\\u2581', ' ')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:09.754632913Z",
     "start_time": "2023-12-22T20:48:09.745545811Z"
    }
   },
   "id": "ac2241fbc35813e5",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "\n",
    "class XLMRForTC(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            **kwargs)\n",
    "        # print(outputs)\n",
    "        # print(outputs[0])\n",
    "        seq_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(seq_output)\n",
    "        # print(logits.shape)\n",
    "              \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            # print(labels.shape)\n",
    "            # print(logits.dtype, labels.dtype)\n",
    "            loss = loss_fn(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:10.128797317Z",
     "start_time": "2023-12-22T20:48:09.752450816Z"
    }
   },
   "id": "cd966c35b80db3de",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags.names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:10.131964540Z",
     "start_time": "2023-12-22T20:48:10.129937138Z"
    }
   },
   "id": "ae35c0a9fd2e54c3",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "index2tag = {i : t for i, t in enumerate(tags.names)}\n",
    "tag2index = {t : i for i, t in enumerate(tags.names)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:10.175253609Z",
     "start_time": "2023-12-22T20:48:10.132995507Z"
    }
   },
   "id": "67b97f836b3eb275",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
    "                                         num_labels=tags.num_classes,\n",
    "                                         id2label=index2tag,\n",
    "                                         label2id=tag2index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:10.243088461Z",
     "start_time": "2023-12-22T20:48:10.173584650Z"
    }
   },
   "id": "f1bae1fea667fd73",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRForTC were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "xlmr_model = XLMRForTC.from_pretrained(xlmr_model_name, config=xlmr_config).to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:11.279064826Z",
     "start_time": "2023-12-22T20:48:10.298722899Z"
    }
   },
   "id": "4eb1986d3260ce5c",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "{'input_ids': [0, 21763, 37456, 15555, 5161, 7, 2356, 5753, 38, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer(text)\n",
    "input_ids"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:11.286449559Z",
     "start_time": "2023-12-22T20:48:11.280248758Z"
    }
   },
   "id": "e34f047e30f643f",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     0      1      2      3      4  5     6      7   8     9\n0  <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n1    0  21763  37456  15555   5161  7  2356   5753  38     2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>21763</td>\n      <td>37456</td>\n      <td>15555</td>\n      <td>5161</td>\n      <td>7</td>\n      <td>2356</td>\n      <td>5753</td>\n      <td>38</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_tokens, input_ids.numpy()[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:11.327169106Z",
     "start_time": "2023-12-22T20:48:11.282647784Z"
    }
   },
   "id": "1414af9b62e1738a",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     0      1      2      3      4      5      6      7      8     9\n0  <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !  </s>\n1    O  B-PER  B-PER  B-PER  B-ORG  B-PER  B-PER  B-PER  B-PER     O",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>O</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>B-ORG</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device), labels=torch.ones(1, 10, dtype=torch.long).to(device))\n",
    "predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "preds = [index2tag[i] for i in predictions.to('cpu').numpy()[0]]\n",
    "pd.DataFrame([xlmr_tokens, preds])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:11.562558976Z",
     "start_time": "2023-12-22T20:48:11.325671423Z"
    }
   },
   "id": "b75d23ca42734449",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "     0      1      2      3      4      5      6      7      8     9\n0  <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !  </s>\n1    O  B-PER  B-PER  B-PER  B-ORG  B-PER  B-PER  B-PER  B-PER     O",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;s&gt;</td>\n      <td>▁Jack</td>\n      <td>▁Spar</td>\n      <td>row</td>\n      <td>▁love</td>\n      <td>s</td>\n      <td>▁New</td>\n      <td>▁York</td>\n      <td>!</td>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>O</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>B-ORG</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>B-PER</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    outputs = model(input_ids)\n",
    "    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "    preds = [tags.names[i] for i in predictions.to('cpu').numpy()[0]]\n",
    "    return pd.DataFrame([tokens, preds])\n",
    "    \n",
    "tag_text(text, tags, xlmr_model, xlmr_tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T20:48:11.653561612Z",
     "start_time": "2023-12-22T20:48:11.563490989Z"
    }
   },
   "id": "ade1d53a02eeaeaa",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def xlmr_tags(raw_tags, word_ids):\n",
    "    tags = []\n",
    "    word_id_prev = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id is None or word_id == word_id_prev:\n",
    "            tags.append(-100)\n",
    "        else:\n",
    "            tags.append(raw_tags[word_id])\n",
    "        word_id_prev = word_id\n",
    "    return tags\n",
    "\n",
    "def tokenize_xlmr(batch):\n",
    "    xlmr_tokens = xlmr_tokenizer(batch['tokens'], truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    labels = []\n",
    "    for i, raw_tags in enumerate(batch['ner_tags']):\n",
    "        labels.append(xlmr_tags(raw_tags, xlmr_tokens.word_ids(i)))\n",
    "    xlmr_tokens['labels'] = labels\n",
    "    \n",
    "    return xlmr_tokens\n",
    "\n",
    "panx_de_encoded = panx_ch['de'].map(tokenize_xlmr, batched=True, remove_columns=['langs', 'ner_tags', 'tokens'])\n",
    "\n",
    "random_i = random.randint(0, panx_de_encoded['train'].shape[0])\n",
    "x1 = panx_de_encoded['train']['input_ids'][random_i]\n",
    "y1 = panx_de_encoded['train']['labels'][random_i]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T22:43:04.501231079Z",
     "start_time": "2023-12-22T22:43:04.340359693Z"
    }
   },
   "id": "9ff3446eb3ceee5d",
   "execution_count": 139
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "    0       1      2     3    4     5      6      7      8      9    10  \\\n0    0  107626  67872  1329  749  2388  22003  73387  25421  13228  168   \n1    0  107626  67872  1329  749  2388  22003  73387  25421  13228  168   \n2 -100       0      0     0    0     0      0      0   -100      0    0   \n3 -100       0      0     0    0     0      0      0   -100      0    0   \n\n      11     12     13     14   15     16  17   18   19  \n0  80192  27262  15934  80748  142  50016   6    5    2  \n1  80192  27262  15934  80748  142  50016   6    5    2  \n2      3      4   -100      4    0   -100   0 -100 -100  \n3      3      4   -100      4    0   -100   0 -100 -100  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>107626</td>\n      <td>67872</td>\n      <td>1329</td>\n      <td>749</td>\n      <td>2388</td>\n      <td>22003</td>\n      <td>73387</td>\n      <td>25421</td>\n      <td>13228</td>\n      <td>168</td>\n      <td>80192</td>\n      <td>27262</td>\n      <td>15934</td>\n      <td>80748</td>\n      <td>142</td>\n      <td>50016</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>107626</td>\n      <td>67872</td>\n      <td>1329</td>\n      <td>749</td>\n      <td>2388</td>\n      <td>22003</td>\n      <td>73387</td>\n      <td>25421</td>\n      <td>13228</td>\n      <td>168</td>\n      <td>80192</td>\n      <td>27262</td>\n      <td>15934</td>\n      <td>80748</td>\n      <td>142</td>\n      <td>50016</td>\n      <td>6</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>-100</td>\n      <td>4</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>-100</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>4</td>\n      <td>-100</td>\n      <td>4</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>0</td>\n      <td>-100</td>\n      <td>-100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, \n",
    "                                      is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True, \n",
    "                      remove_columns=['langs', 'ner_tags', 'tokens'])\n",
    "\n",
    "# hide_output\n",
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])\n",
    "\n",
    "x2 = panx_de_encoded['train']['input_ids'][random_i]\n",
    "y2 = panx_de_encoded['train']['labels'][random_i]\n",
    "\n",
    "pd.DataFrame([x1, x2, y1, y2])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-22T22:43:05.256980520Z",
     "start_time": "2023-12-22T22:43:05.109225474Z"
    }
   },
   "id": "89c62cfffc120459",
   "execution_count": 140
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "638456bc2b2820c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
